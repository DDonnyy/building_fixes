{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import osm2geojson\n",
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "import momepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from IPython import display\n",
    "from shapely.ops import nearest_points,substring\n",
    "from shapely import from_wkt,Point,wkt,LineString,geometry\n",
    "from fiona.errors import DriverError\n",
    "from itertools import chain\n",
    "import requests\n",
    "import time\n",
    "from json import JSONDecodeError\n",
    "tqdm.pandas()\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "def get_boundary(osm_id):\n",
    "\n",
    "    overpass_url = \"http://lz4.overpass-api.de/api/interpreter\"\n",
    "    overpass_query = f\"\"\"\n",
    "    [out:json];\n",
    "            (\n",
    "              relation({osm_id});\n",
    "            );\n",
    "    out geom;\n",
    "    \"\"\"\n",
    "    result = requests.get(overpass_url, params={'data': overpass_query})\n",
    "    json_result = result.json()\n",
    "\n",
    "    return json_result\n",
    "\n",
    "\n",
    "def get_routes(osm_id, public_transport_type):\n",
    "\n",
    "    overpass_url = \"http://lz4.overpass-api.de/api/interpreter\"\n",
    "    overpass_query = f\"\"\"\n",
    "    [out:json];\n",
    "            (\n",
    "                relation({osm_id});\n",
    "            );map_to_area;\n",
    "            (\n",
    "                relation(area)['route'='{public_transport_type}'];\n",
    "            );\n",
    "    out geom;\n",
    "    \"\"\"\n",
    "    result = requests.get(overpass_url, params={'data': overpass_query})\n",
    "    json_result = result.json()[\"elements\"]\n",
    "\n",
    "    return pd.DataFrame(json_result)\n",
    "\n",
    "\n",
    "def overpass_query(func, *args, attempts=5):\n",
    "\n",
    "    for i in range(attempts):\n",
    "        try:\n",
    "            return func(*args)\n",
    "        except JSONDecodeError:\n",
    "            print(\"Another attempt to get response from Overpass API...\")\n",
    "            time.sleep(20)\n",
    "            continue\n",
    "\n",
    "    raise SystemError(\n",
    "    \"\"\"Something went wrong with Overpass API when JSON was parsed. Check the query and to send it later.\"\"\")\n",
    "\n",
    "\n",
    "def parse_overpass_route_response(loc, city_crs, boundary):\n",
    "\n",
    "    route = pd.DataFrame(loc['members'])\n",
    "    ways = route[route['type'] == 'way']\n",
    "    if len(ways) > 0:\n",
    "        ways = ways['geometry'].reset_index(drop = True)\n",
    "        ways = ways.apply(lambda x: pd.DataFrame(x))\n",
    "        ways = ways.apply(lambda x: LineString(list(zip(x['lon'], x['lat']))))\n",
    "        ways = gpd.GeoDataFrame(ways.rename(\"geometry\")).set_crs(4326)\n",
    "        if ways.within(boundary).all():\n",
    "            # fix topological errors and then make LineString from MultiLineString\n",
    "            ways = get_linestring(ways.to_crs(city_crs))\n",
    "        else:\n",
    "            ways = None\n",
    "    else:\n",
    "        ways = None\n",
    "\n",
    "    if \"node\" in route[\"type\"].unique():\n",
    "        platforms = route[route['type'] == 'node'][[\"lat\", \"lon\"]].reset_index(drop = True)\n",
    "        platforms = platforms.apply(lambda x: Point(x[\"lon\"], x[\"lat\"]), axis=1)\n",
    "    else:\n",
    "        platforms = None\n",
    "\n",
    "    return pd.Series({\"way\": ways, \"platforms\": platforms})\n",
    "\n",
    "\n",
    "def get_linestring(route):\n",
    "\n",
    "    equal_lines = route.apply(lambda x: find_equals_line(x, route), axis=1).dropna()\n",
    "    lines_todel = list(chain(*[line[1:] for line in list(equal_lines)]))\n",
    "    route = route.drop(lines_todel).reset_index()\n",
    "\n",
    "    path_buff = gpd.GeoSeries(route.geometry.buffer(0.01))\n",
    "    connect_series = route.apply(lambda x: find_connection(x, path_buff), axis=1).dropna()\n",
    "    sequences = get_sequences(connect_series, [])\n",
    "    if sequences is None:\n",
    "        return None\n",
    "\n",
    "    len_sequence = [len(sec) for sec in sequences]\n",
    "    max_sequence = len_sequence.index(max(len_sequence))\n",
    "    sequence = sequences[max_sequence]\n",
    "    comlete_line = [route.geometry[sequence[0]]]\n",
    "\n",
    "    for i in range(len(sequence) - 1):\n",
    "        line1 = comlete_line[i]\n",
    "        line2 = route.geometry[sequence[i + 1]]\n",
    "        con_point1, con_point2 = nearest_points(line1, line2)\n",
    "\n",
    "        line2 = list(line2.coords)\n",
    "        check_reverse = gpd.GeoSeries([Point(line2[0]), Point(line2[-1])]).distance(con_point2).idxmin()\n",
    "        if check_reverse == 1:\n",
    "            line2.reverse()\n",
    "\n",
    "        comlete_line.append(LineString(line2))\n",
    "\n",
    "    comlete_line = list(chain(*[list(line.coords) for line in comlete_line]))\n",
    "    comlete_line = list(pd.Series(comlete_line).drop_duplicates())\n",
    "\n",
    "    return LineString(comlete_line)\n",
    "\n",
    "\n",
    "def find_equals_line(loc, series):\n",
    "\n",
    "    series = series.drop(loc.name)\n",
    "    eq_lines = series.geometry.apply(lambda x: x.almost_equals(loc.geometry))\n",
    "    eq_lines = series[eq_lines].index\n",
    "\n",
    "    equal_lines = sorted(list(eq_lines) + [loc.name]) if len(eq_lines) > 0 else None\n",
    "\n",
    "    return equal_lines\n",
    "\n",
    "\n",
    "def find_connection(loc, df):\n",
    "\n",
    "    df = df.drop(loc.name)\n",
    "    bool_ser = df.intersects(loc.geometry)\n",
    "    connect_lines = df[bool_ser].index\n",
    "\n",
    "    if len(connect_lines) > 0:\n",
    "        return list(connect_lines)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_sequences(connect_ser, sequences=[]):\n",
    "\n",
    "    num_con = connect_ser.apply(lambda x: len(x))\n",
    "    finite_points = pd.DataFrame(connect_ser[num_con == 1].rename(\"value\"))\n",
    "\n",
    "    if len(finite_points) == 0:\n",
    "        return None\n",
    "\n",
    "    sequence = move_next(finite_points.index[0], connect_ser, [])\n",
    "    sequences.append(sequence)\n",
    "\n",
    "    route_finite = finite_points.index.isin(sequence)\n",
    "    if route_finite.all():\n",
    "        return sequences\n",
    "    else:\n",
    "        connect_ser = connect_ser.drop(finite_points.index[route_finite])\n",
    "        sequences = get_sequences(connect_ser, sequences)\n",
    "        return sequences\n",
    "\n",
    "def move_next(path, series, sequence, branching=None):\n",
    "\n",
    "    sequence.append(path)\n",
    "    try:\n",
    "        series = series.drop(path)\n",
    "    except: pass\n",
    "    bool_next_path = series.apply(lambda x: path in x)\n",
    "    next_path = series[bool_next_path].index\n",
    "\n",
    "    if len(next_path) == 0:\n",
    "        return sequence\n",
    "\n",
    "    elif len(next_path) > 1:\n",
    "\n",
    "        if branching is None:\n",
    "            branches_start = path\n",
    "            sequence_variance = []\n",
    "            for path in next_path:\n",
    "                series_ = series.drop([path_ for path_ in next_path if path_ != path])\n",
    "                sequence_ = move_next(path, series_, [], branches_start)\n",
    "                sequence_variance.append(sequence_)\n",
    "\n",
    "        else:\n",
    "            return sequence\n",
    "\n",
    "        len_sequence = [len(sec) for sec in sequence_variance]\n",
    "        max_sequence = len_sequence.index(max(len_sequence))\n",
    "        sequence_ = sequence_variance[max_sequence]\n",
    "        series_ = series.drop(list(chain(*[sec[-2:] for sec in sequence_variance])))\n",
    "        sequence = sequence + sequence_\n",
    "        sequence_ = move_next(sequence_[-1], series_, sequence_, None)\n",
    "        return sequence + sequence_\n",
    "\n",
    "    else:\n",
    "        sequence = move_next(next_path[0], series, sequence, branching)\n",
    "    return sequence\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Function project_platforms and its supplementary functions are used to project points on lines.\n",
    "It is a necessary operation since OpenStreetMap contains two types of points describing\n",
    "public transport stops - 'stop' and 'platforms'. The points marked as 'platform' usually\n",
    "do not lie on route lines. Moreover some of them are very close to each other and probably\n",
    "mean the same stop. To check this, 'project_threshold' value and recursion function are used.\n",
    "\n",
    "Function project_platforms takes two arguments - 'loc' which is Series contains rows 'platforms' and 'way'\n",
    "and 'city_crs'. 'way' is shapely LineString object, and 'platforms' is Series of shapely Point objects\n",
    "\n",
    "loc: Series object\n",
    "city_crs: int\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def project_platforms(loc, city_crs):\n",
    "\n",
    "    project_threshold = 5\n",
    "    edge_indent = 10\n",
    "\n",
    "    platforms = loc[\"platforms\"]\n",
    "    line = loc[\"way\"]\n",
    "    line_length = line.length\n",
    "\n",
    "    if platforms is not None:\n",
    "        platforms = gpd.GeoSeries(platforms).set_crs(4326).to_crs(city_crs)\n",
    "        stops = platforms.apply(lambda x: nearest_points(line, x)[0])\n",
    "        stops = gpd.GeoDataFrame(stops).rename(columns={0:\"geometry\"}).set_geometry(\"geometry\")\n",
    "        stops = recursion(stops, project_threshold)\n",
    "\n",
    "        check_reverse = gpd.GeoSeries([Point(line.coords[0]), Point(line.coords[-1])]).distance(stops[0]).idxmin()\n",
    "        if check_reverse == 1:\n",
    "            line = list(line.coords)\n",
    "            line.reverse()\n",
    "            line = LineString(line)\n",
    "\n",
    "        stops_distance = stops.apply(lambda x: line.project(x)).sort_values()\n",
    "        stops = stops.loc[stops_distance.index]\n",
    "        condition = (stops_distance > edge_indent)&(stops_distance < line_length - edge_indent)\n",
    "        stops, distance = stops[condition].reset_index(drop=True), [0] + list(stops_distance[condition])\n",
    "        distance.append(line_length)\n",
    "\n",
    "        if len(stops) > 0:\n",
    "            start_line = gpd.GeoSeries(Point(line.coords[0])).set_crs(city_crs)\n",
    "            end_line = gpd.GeoSeries(Point(line.coords[-1])).set_crs(city_crs)\n",
    "            stops = pd.concat([start_line, stops, end_line]).reset_index(drop=True)\n",
    "        else:\n",
    "            stops, distance = get_line_from_start_to_end(line, line_length)\n",
    "    else:\n",
    "        stops, distance = get_line_from_start_to_end(line, line_length)\n",
    "\n",
    "    pathes = [[tuple(round(c, 2) for c in stops[i].coords[0]),\n",
    "               tuple(round(c, 2) for c in stops[i + 1].coords[0])]\n",
    "               for i in range(len(stops) - 1)]\n",
    "\n",
    "    return pd.Series({\"pathes\": pathes, \"distance\": distance})\n",
    "\n",
    "\n",
    "def recursion (stops, threshold):\n",
    "\n",
    "    stops['to_del'] = stops.apply(lambda x: get_index_to_delete(stops, x, threshold), axis = 1)\n",
    "\n",
    "    if stops['to_del'].isna().all():\n",
    "        return stops[\"geometry\"]\n",
    "    else:\n",
    "        stops_near_pair = stops.dropna().apply(lambda x: sorted([x.name, x.to_del]), axis=1)\n",
    "        stops_to_del = [pair[0] for pair in stops_near_pair]\n",
    "        stops = stops.drop(stops_to_del)\n",
    "        stops = recursion(stops, threshold)\n",
    "\n",
    "    return stops.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def get_index_to_delete(other_stops, loc_stop, threshold):\n",
    "\n",
    "    stops_to_del = other_stops.geometry.distance(loc_stop.geometry).sort_values().drop(loc_stop.name)\n",
    "    stops_to_del = list(stops_to_del[stops_to_del < threshold].index)\n",
    "\n",
    "    if len(stops_to_del) > 0:\n",
    "        return stops_to_del[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_line_from_start_to_end(line, line_length):\n",
    "\n",
    "    start_line = gpd.GeoSeries(Point(line.coords[0]))\n",
    "    end_line = gpd.GeoSeries(Point(line.coords[-1]))\n",
    "    stops = pd.concat([start_line, end_line]).reset_index(drop=True)\n",
    "    distance = [0, line_length]\n",
    "\n",
    "    return stops, distance\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "These bunch of functions are used to make spatial union of two graphs.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def get_nearest_edge_geometry(points, G):\n",
    "\n",
    "    G = G.edge_subgraph([(u, v, n) for u, v, n, e in G.edges(data=True, keys=True) if e[\"type\"] == \"walk\"])\n",
    "    G = convert_geometry(G.copy())\n",
    "    coords = list(points.geometry.apply(lambda x: list(x.coords)[0]))\n",
    "    x = [c[0] for c in list(coords)]\n",
    "    y = [c[1] for c in list(coords)]\n",
    "    edges, distance = ox.distance.nearest_edges(G, x, y, return_dist=True)\n",
    "    edges_geom = list(map(lambda x: (x, G[x[0]][x[1]][x[2]][\"geometry\"]), edges))\n",
    "    edges_geom = pd.DataFrame(edges_geom, index=points.index, columns=[\"edge_id\", \"edge_geometry\"])\n",
    "    edges_geom[\"distance_to_edge\"] = distance\n",
    "    return pd.concat([points, edges_geom], axis=1)\n",
    "\n",
    "def convert_geometry(graph):\n",
    "    for u, v, n, data in graph.edges(data=True, keys=True):\n",
    "        data[\"geometry\"] = wkt.loads(data[\"geometry\"])\n",
    "    return graph\n",
    "\n",
    "def project_point_on_edge(points_edge_geom):\n",
    "\n",
    "    points_edge_geom[\"nearest_point_geometry\"] = points_edge_geom.apply(\n",
    "        lambda x: nearest_points(x.edge_geometry, x.geometry)[0], axis=1)\n",
    "    points_edge_geom[\"len\"] = points_edge_geom.apply(\n",
    "        lambda x: x.edge_geometry.length, axis=1)\n",
    "    points_edge_geom[\"len_from_start\"] = points_edge_geom.apply(\n",
    "        lambda x: x.edge_geometry.project(x.geometry) , axis=1)\n",
    "    points_edge_geom[\"len_to_end\"] = points_edge_geom.apply(\n",
    "        lambda x: x.edge_geometry.length - x.len_from_start, axis=1)\n",
    "\n",
    "    return points_edge_geom\n",
    "\n",
    "\n",
    "def update_edges(points_info, G):\n",
    "\n",
    "    G_with_drop_edges = delete_edges(points_info, G)\n",
    "    updated_G, split_points = add_splitted_edges(G_with_drop_edges, points_info)\n",
    "    updated_G, split_points = add_connecting_edges(updated_G, split_points)\n",
    "\n",
    "    return updated_G, split_points\n",
    "\n",
    "\n",
    "def delete_edges(project_points, G):\n",
    "\n",
    "    bunch_edges = []\n",
    "    G_copy = convert_geometry(G.copy())\n",
    "    for e in list(project_points[\"edge_id\"]):\n",
    "        flag = check_parallel_edge(G_copy, *e)\n",
    "        if flag == 2:\n",
    "            bunch_edges.extend([(e[0], e[1], e[2]), (e[1], e[0], e[2])])\n",
    "        else:\n",
    "            bunch_edges.append((e[0], e[1], e[2]))\n",
    "\n",
    "    bunch_edges = list(set(bunch_edges))\n",
    "    G.remove_edges_from(bunch_edges)\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "def check_parallel_edge(G, u, v, n):\n",
    "\n",
    "    if u == v:\n",
    "        return 1\n",
    "    elif G.has_edge(u, v) and G.has_edge(v, u):\n",
    "        if G[u][v][n][\"geometry\"].equals(G[v][u][n][\"geometry\"]):\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "\n",
    "def add_splitted_edges(G, split_nodes):\n",
    "\n",
    "    start_node_idx = max((G.nodes)) + 1\n",
    "    split_nodes[\"node_id\"] = range(start_node_idx, start_node_idx + len(split_nodes))\n",
    "    nodes_bunch = split_nodes.apply(lambda x: generate_nodes_bunch(x), axis=1)\n",
    "    nodes_attr = split_nodes.set_index(\"node_id\").nearest_point_geometry.apply(\n",
    "        lambda x: {\"x\": round(list(x.coords)[0][0], 2), \"y\": round(list(x.coords)[0][1], 2)}).to_dict()\n",
    "    G.add_edges_from(list(nodes_bunch.explode()))\n",
    "    nx.set_node_attributes(G, nodes_attr)\n",
    "\n",
    "    return G, split_nodes\n",
    "\n",
    "\n",
    "def generate_nodes_bunch(split_point):\n",
    "\n",
    "    edge_pair = []\n",
    "    edge_nodes = split_point.edge_id\n",
    "    edge_geom_ = split_point.edge_geometry\n",
    "    new_node_id = split_point.node_id\n",
    "    len_from_start = split_point.len_from_start\n",
    "    len_to_end = split_point.len_to_end\n",
    "    len_edge = split_point.len\n",
    "\n",
    "    fst_edge_attr = {\n",
    "        'length_meter': len_from_start, \"geometry\": str(substring(edge_geom_, 0, len_from_start)), \"type\": \"walk\",\n",
    "        }\n",
    "    snd_edge_attr = {\n",
    "        'length_meter': len_to_end, \"geometry\": str(substring(edge_geom_, len_from_start, len_edge)), \"type\": \"walk\",\n",
    "        }\n",
    "    edge_pair.extend([(edge_nodes[0], new_node_id, fst_edge_attr),(new_node_id, edge_nodes[0], fst_edge_attr),\n",
    "                      (new_node_id, edge_nodes[1], snd_edge_attr), (edge_nodes[1], new_node_id, snd_edge_attr)])\n",
    "\n",
    "    return edge_pair\n",
    "\n",
    "\n",
    "def add_connecting_edges(G, split_nodes):\n",
    "\n",
    "    start_node_idx = split_nodes[\"node_id\"].max() + 1\n",
    "    split_nodes[\"connecting_node_id\"] = list(range(start_node_idx, start_node_idx + len(split_nodes)))\n",
    "    nodes_attr = split_nodes.set_index(\"connecting_node_id\").geometry.apply(\n",
    "        lambda p: {\"x\": round(p.coords[0][0], 2), \"y\": round(p.coords[0][1], 2)}\n",
    "        ).to_dict()\n",
    "    conn_edges = split_nodes.apply(\n",
    "        lambda x: (x.node_id, x.connecting_node_id, {\n",
    "            \"type\": \"walk\", \"length_meter\": round(x.distance_to_edge, 3),\n",
    "            \"geometry\": str(LineString([x.geometry, x.nearest_point_geometry]))\n",
    "            }), axis=1)\n",
    "    conn_edges_another_direct = conn_edges.apply(lambda x: (x[1], x[0], x[2]))\n",
    "    G.add_edges_from(conn_edges.tolist() + conn_edges_another_direct.tolist())\n",
    "    nx.set_node_attributes(G, nodes_attr)\n",
    "    return G, split_nodes\n",
    "\n",
    "\n",
    "def join_graph(G_base, G_to_project, points_df):\n",
    "\n",
    "    new_nodes = points_df.set_index(\"node_id_to_project\")[\"connecting_node_id\"]\n",
    "    for n1, n2, d in tqdm(G_to_project.edges(data=True)):\n",
    "        G_base.add_edge(int(new_nodes[n1]), int(new_nodes[n2]), **d)\n",
    "        nx.set_node_attributes(\n",
    "            G_base, {int(new_nodes[n1]): G_to_project.nodes[n1], int(new_nodes[n2]): G_to_project.nodes[n2]}\n",
    "            )\n",
    "\n",
    "    return G_base\n",
    "\n",
    "def get_osmnx_graph(city_osm_id, city_crs, graph_type, speed=None):\n",
    "\n",
    "    boundary = overpass_query(get_boundary, city_osm_id)\n",
    "    boundary = osm2geojson.json2geojson(boundary)\n",
    "    boundary = gpd.GeoDataFrame.from_features(boundary[\"features\"]).set_crs(4326)\n",
    "\n",
    "    print(f\"Extracting and preparing {graph_type} graph...\")\n",
    "    G_ox = ox.graph.graph_from_polygon(polygon=boundary[\"geometry\"][0], network_type=graph_type)\n",
    "    G_ox.graph[\"approach\"] = \"primal\"\n",
    "\n",
    "    nodes, edges = momepy.nx_to_gdf(G_ox, points=True, lines=True, spatial_weights=False)\n",
    "    nodes = nodes.to_crs(city_crs).set_index(\"nodeID\")\n",
    "    nodes_coord = nodes.geometry.apply(\n",
    "        lambda p: {\"x\": round(p.coords[0][0], 2), \"y\": round(p.coords[0][1], 2)}\n",
    "        ).to_dict()\n",
    "\n",
    "    edges = edges[[\"length\", \"node_start\", \"node_end\", \"geometry\"]].to_crs(city_crs)\n",
    "    edges[\"type\"] = graph_type\n",
    "    edges[\"geometry\"] = edges[\"geometry\"].apply(\n",
    "        lambda x: LineString([tuple(round(c, 2) for c in n) for n in x.coords] if x else None)\n",
    "        )\n",
    "\n",
    "    travel_type = \"walk\" if graph_type == \"walk\" else \"car\"\n",
    "    if not speed:\n",
    "        speed =  4 * 1000 / 60 if graph_type == \"walk\" else  17 * 1000 / 60\n",
    "\n",
    "    G = nx.MultiDiGraph()\n",
    "    for i, edge in tqdm(edges.iterrows(), total=len(edges)):\n",
    "        p1 = int(edge.node_start)\n",
    "        p2 = int(edge.node_end)\n",
    "        geometry = LineString(\n",
    "            ([(nodes_coord[p1][\"x\"], nodes_coord[p1][\"y\"]), (nodes_coord[p2][\"x\"], nodes_coord[p2][\"y\"])])\n",
    "            ) if not edge.geometry else edge.geometry\n",
    "        G.add_edge(\n",
    "            p1, p2, length_meter=edge.length, geometry=str(geometry), type = travel_type,\n",
    "            time_min = round(edge.length / speed, 2)\n",
    "            )\n",
    "    nx.set_node_attributes(G, nodes_coord)\n",
    "    G.graph['crs'] = 'epsg:' + str(city_crs)\n",
    "    G.graph['graph_type'] = travel_type + \" graph\"\n",
    "    G.graph[travel_type + ' speed'] = round(speed, 2)\n",
    "\n",
    "    print(f\"{graph_type.capitalize()} graph done!\")\n",
    "    return G\n",
    "\n",
    "def public_routes_to_edges(city_osm_id, city_crs, transport_type, speed, boundary):\n",
    "    routes = overpass_query(get_routes, city_osm_id, transport_type)\n",
    "    print(f\"Extracting and preparing {transport_type} routes:\")\n",
    "\n",
    "    try:\n",
    "        df_routes = routes.progress_apply(\n",
    "            lambda x: parse_overpass_route_response(x, city_crs, boundary), axis = 1, result_type=\"expand\"\n",
    "            )\n",
    "        df_routes = gpd.GeoDataFrame(df_routes).dropna(subset=[\"way\"]).set_geometry(\"way\")\n",
    "\n",
    "    except KeyError:\n",
    "        print(f\"It seems there are no {transport_type} routes in the city. This transport type will be skipped.\")\n",
    "        return []\n",
    "\n",
    "    # some stops don't lie on lines, therefore it's needed to project them\n",
    "    stop_points = df_routes.apply(lambda x: project_platforms(x, city_crs), axis = 1)\n",
    "\n",
    "    edges = []\n",
    "    time_on_stop = 1\n",
    "    for i, route in stop_points.iterrows():\n",
    "        length = np.diff(list(route[\"distance\"]))\n",
    "        for j in range(len(route[\"pathes\"])):\n",
    "            edge_length = float(length[j])\n",
    "            p1 = route[\"pathes\"][j][0]\n",
    "            p2 = route[\"pathes\"][j][1]\n",
    "            d = {\"time_min\": round(edge_length/speed + time_on_stop, 2), \"length_meter\": round(edge_length, 2),\n",
    "                \"type\": transport_type, \"desc\": f\"route {i}\", \"geometry\": str(LineString([p1, p2]))}\n",
    "            edges.append((p1, p2, d))\n",
    "\n",
    "    return edges\n",
    "\n",
    "def graphs_spatial_union(G_base, G_to_project):\n",
    "    points = gpd.GeoDataFrame([[n, Point((d[\"x\"], d[\"y\"]))] for n, d in G_to_project.nodes(data=True)],\n",
    "                            columns=[\"node_id_to_project\", \"geometry\"])\n",
    "    edges_geom = get_nearest_edge_geometry(points, G_base)\n",
    "    projected_point_info = project_point_on_edge(edges_geom)\n",
    "    check_point_on_line = projected_point_info.apply(\n",
    "        lambda x: x.edge_geometry.buffer(1).contains(x.nearest_point_geometry), axis=1).all()\n",
    "    if not check_point_on_line:\n",
    "        raise ValueError(\"Some projected points don't lie on edges\")\n",
    "    points_on_lines = projected_point_info[(projected_point_info[\"len_from_start\"] != 0)\n",
    "                                            & (projected_point_info[\"len_to_end\"] != 0)]\n",
    "\n",
    "    points_on_points = projected_point_info[~projected_point_info.index.isin(points_on_lines.index)]\n",
    "    try:\n",
    "        points_on_points[\"connecting_node_id\"] = points_on_points.apply(\n",
    "            lambda x: x.edge_id[0] if x.len_from_start == 0 else x.edge_id[1], axis=1\n",
    "        )\n",
    "    except ValueError:\n",
    "        print(\"No matching nodes were detected, seems like your data is not the same as in OSM. \")\n",
    "\n",
    "    updated_G_base, points_on_lines = update_edges(points_on_lines, G_base)\n",
    "    points_df = pd.concat([points_on_lines, points_on_points])\n",
    "    united_graph = join_graph(updated_G_base, G_to_project, points_df)\n",
    "    return united_graph\n",
    "\n",
    "def get_intermodal_graph(city_osm_id, city_crs, gdf_files, public_transport_speeds=None, walk_speed=None,\n",
    "                         drive_speed=None):\n",
    "    G_public_transport: nx.MultiDiGraph = get_public_trasport_graph(city_osm_id, city_crs, gdf_files,\n",
    "                                                                    public_transport_speeds)\n",
    "    G_walk: nx.MultiDiGraph = get_osmnx_graph(city_osm_id, city_crs, \"walk\", speed=walk_speed)\n",
    "\n",
    "    G_drive: nx.MultiDiGraph = get_osmnx_graph(city_osm_id, city_crs, \"drive\", speed=drive_speed)\n",
    "    print(\"Union of graphs...\")\n",
    "    G_intermodal = graphs_spatial_union(G_walk, G_drive)\n",
    "    if G_public_transport.number_of_edges() > 0:\n",
    "        G_intermodal = graphs_spatial_union(G_intermodal, G_public_transport)\n",
    "\n",
    "    for u, v, d in G_intermodal.edges(data=True):\n",
    "        if \"time_min\" not in d:\n",
    "            d[\"time_min\"] = round(d[\"length_meter\"] / G_walk.graph[\"walk speed\"], 2)\n",
    "        if \"desc\" not in d:\n",
    "            d[\"desc\"] = \"\"\n",
    "\n",
    "    for u, d in G_intermodal.nodes(data=True):\n",
    "        if \"stop\" not in d:\n",
    "            d[\"stop\"] = \"False\"\n",
    "        if \"desc\" not in d:\n",
    "            d[\"desc\"] = \"\"\n",
    "\n",
    "    G_intermodal.graph[\"graph_type\"] = \"intermodal graph\"\n",
    "    G_intermodal.graph[\"car speed\"] = G_drive.graph[\"car speed\"]\n",
    "    G_intermodal.graph.update({k: v for k, v in G_public_transport.graph.items() if \"speed\" in k})\n",
    "    G_intermodal.graph[\"created by\"] = \"CityGeoTools\"\n",
    "\n",
    "    print(\"Intermodal graph done!\")\n",
    "    return G_intermodal\n",
    "\n",
    "\n",
    "\n",
    "def get_public_trasport_graph(city_osm_id, city_crs, gdf_files, transport_types_speed=None):\n",
    "    G = nx.MultiDiGraph()\n",
    "    edegs_different_types = []\n",
    "    print(\"\\n\")\n",
    "    if not transport_types_speed:\n",
    "        transport_types_speed = {\n",
    "            \"subway\": 12 * 1000 / 60,\n",
    "            \"tram\": 15 * 1000 / 60,\n",
    "            \"trolleybus\": 12 * 1000 / 60,\n",
    "            \"bus\": 17 * 1000 / 60\n",
    "        }\n",
    "    from_file = False\n",
    "    for transport in gdf_files.values():\n",
    "        if transport.get('stops') or transport.get('routes'):\n",
    "            from_file = True\n",
    "\n",
    "    if not from_file:\n",
    "        print(\"Files with routes or with stops was not found. The graph will be built based on data from OSM\")\n",
    "        boundary = overpass_query(get_boundary, city_osm_id)\n",
    "        boundary = osm2geojson.json2geojson(boundary)\n",
    "        boundary = geometry.shape(boundary['features'][0][\"geometry\"])\n",
    "\n",
    "        for transport_type, speed in transport_types_speed.items():\n",
    "            print(\"Getting public routes data from OSM...\")\n",
    "            edges = public_routes_to_edges(city_osm_id, city_crs, transport_type, speed, boundary)\n",
    "            edegs_different_types.extend(edges)\n",
    "    else:\n",
    "        print(\"Getting public routes data from File...\")\n",
    "        for transport_type, speed in transport_types_speed.items():\n",
    "            files = gdf_files.get(transport_type)\n",
    "            if not files.get(\"routes\") or not files.get(\"stops\"):\n",
    "                print(f\"No data provided for \\\"{transport_type}\\\", skipping this transport type\")\n",
    "                continue\n",
    "            else:\n",
    "                edges = public_routes_to_edges_from_file(city_crs, transport_type, speed, files)\n",
    "                edegs_different_types.extend(edges)\n",
    "\n",
    "    G.add_edges_from(edegs_different_types)\n",
    "    if len(edegs_different_types)==0:\n",
    "        print(f\"No data found for public transport, this graph will be empty.\\n\")\n",
    "        return G\n",
    "\n",
    "    node_attributes = {node: {\n",
    "        \"x\": round(node[0], 2), \"y\": round(node[1], 2), \"stop\": \"True\", \"desc\": []\n",
    "    } for node in list(G.nodes)}\n",
    "\n",
    "    for p1, p2, data in list(G.edges(data=True)):\n",
    "        transport_type = data[\"type\"]\n",
    "        node_attributes[p1][\"desc\"].append(transport_type), node_attributes[p2][\"desc\"].append(transport_type)\n",
    "\n",
    "    for data in node_attributes.values():\n",
    "        data[\"desc\"] = \", \".join(set(data[\"desc\"]))\n",
    "    nx.set_node_attributes(G, node_attributes)\n",
    "    G = nx.convert_node_labels_to_integers(G)\n",
    "    G.graph['crs'] = 'epsg:' + str(city_crs)\n",
    "    G.graph['graph_type'] = \"public transport graph\"\n",
    "    G.graph.update({k + \" speed\": round(v, 2) for k, v in transport_types_speed.items()})\n",
    "\n",
    "    print(\"Public transport graph done!\")\n",
    "    return G\n",
    "\n",
    "def public_routes_to_edges_from_file(city_crs, transport_type, speed, gdf_files):\n",
    "    edges = []\n",
    "    try:\n",
    "        gdf_stops = gpd.read_file(gdf_files.get(\"stops\"))\n",
    "\n",
    "        gdf_routes = gpd.read_file(gdf_files.get(\"routes\"))\n",
    "        ways: gpd.GeoDataFrame = gdf_routes[['route', 'geometry']].copy()\n",
    "        ways = ways.explode(index_parts=False).to_crs(city_crs)\n",
    "        ways[\"route\"] = ways[\"route\"].apply(lambda x: str(x).strip())\n",
    "        ways.set_index('route', inplace=True)\n",
    "\n",
    "        platforms = pd.DataFrame(columns=[\"route\", \"geometry\"])\n",
    "\n",
    "        for index, row in gdf_stops.iterrows():\n",
    "            for i in str(row[\"route\"]).split(\",\"):\n",
    "                df = pd.DataFrame(({i: row[\"geometry\"]}).items(), columns=['route', 'geometry'])\n",
    "                platforms = pd.concat([platforms, df])\n",
    "        platforms.reset_index(inplace=True, drop=True)\n",
    "        platforms[\"route\"] = platforms[\"route\"].apply(lambda x: str(x).strip())\n",
    "        df_routes = pd.DataFrame()\n",
    "\n",
    "        for index, row in ways.iterrows():\n",
    "            platforms_: pd.Series = platforms[platforms[\"route\"] == str(index)].drop('route', axis=1).reset_index(\n",
    "                drop=True).squeeze()\n",
    "            series = pd.Series({'way': row[\"geometry\"], 'platforms': platforms_})\n",
    "            df_routes = pd.concat([df_routes, series], axis=1, ignore_index=True)\n",
    "        df_routes = df_routes.transpose()\n",
    "        df_routes = gpd.GeoDataFrame(df_routes).set_geometry(\"way\")\n",
    "\n",
    "        stop_points = df_routes.apply(lambda x: project_platforms(x, city_crs), axis=1)\n",
    "\n",
    "        time_on_stop = 1\n",
    "        for i, route in stop_points.iterrows():\n",
    "            length = np.diff(list(route[\"distance\"]))\n",
    "            for j in range(len(route[\"pathes\"])):\n",
    "                edge_length = float(length[j])\n",
    "                p1 = route[\"pathes\"][j][0]\n",
    "                p2 = route[\"pathes\"][j][1]\n",
    "                d = {\"time_min\": round(edge_length / speed + time_on_stop, 2), \"length_meter\": round(edge_length, 2),\n",
    "                     \"type\": transport_type, \"desc\": f\"route {i}\", \"geometry\": str(LineString([p1, p2]))}\n",
    "                edges.append((p1, p2, d))\n",
    "    except KeyError:\n",
    "        print(f\"! ! !\\nThe 'route' column was not found in one of the files for \\\"{transport_type}\\\" . Please check their contents.\\n! ! !\")\n",
    "    except Exception as err:\n",
    "        print(f\"! ! !\\nFile with routes or with stops was not found for \\\"{transport_type}\\\", error:\",err,\"\\n! ! !\")\n",
    "    finally:\n",
    "        return edges"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8da3bc9e12e9265"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "city_osm_id = 7656650\n",
    "city_crs = 32643\n",
    "\"\"\"\n",
    "If you need to upload public transportation data from a file, please fill in the dictionary below.\n",
    "Leave 'None' in case of no file or provide the file name with the .geojson format.\n",
    "For example:\n",
    "\"bus\": {\"stops\": \"bus_stop_Tara.geojson\", \"routes\": \"Tara_routes.geojson\"}\n",
    "OR\n",
    "\"bus\": {\"stops\": None, \"routes\": None}\"\n",
    "\"\"\"\n",
    "gdf_files = {\n",
    "    \"subway\": {\"stops\": None, \"routes\": None},\n",
    "\n",
    "    \"tram\": {\"stops\": None, \"routes\": None},\n",
    "\n",
    "    \"trolleybus\": {\"stops\": None, \"routes\": None},\n",
    "\n",
    "    \"bus\": {\"stops\": \"bus_stop_Tara.geojson\", \"routes\": \"Тара_маршруты.geojson\"}\n",
    "}\n",
    "\n",
    "G_graph: nx.MultiDiGraph = get_intermodal_graph(city_osm_id, city_crs, gdf_files)\n",
    "nx.write_graphml(G_graph, f'{city_osm_id}.graphml')\n",
    "for i in G_graph.edges(data=True):\n",
    "    i[2]['geometry'] = from_wkt(str(i[2]['geometry']))\n",
    "ec = ['y' if 'walk' in d['type'] else 'r' if 'car' in d['type'] else 'b' for _, _, _, d in\n",
    "      G_graph.edges(keys=True, data=True)]\n",
    "ox.plot_graph(G_graph, edge_color=ec, dpi=300, save=True, filepath=f\"{city_osm_id}.png\", node_size=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69ed6b4507707caa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
